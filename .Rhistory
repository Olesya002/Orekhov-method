if (all.equal(vect, temp) == 'TRUE') {
return(T)
} else{
return(F)
}
}
equal(test[1,4], 1)
equal(test[1,4], 2)
m <- apply(test, 2, function(x) any(sapply(x, function(y) equal(abs(y),1))))
m
colnames(test)[apply(m,2,function(x) any(x) == T)]
colnames(test)
colnames(test)[m]
is_multicol <- function(d){
test <- cor(d)
diag(test) <- rep(0,nrow(test))
m <- apply(test, 2, function(x) sapply(x, function(y) equal(abs(y),1)))
res <- colnames(test)[m]
if (length(res) > 0) res else "There is no collinearity in the data"
}
is_multicol(test_data)
test_data <- as.data.frame(list(V1 = c(20, 11, 17, 7, 28), V2 = c(9, 23, 18, 6, 7), V3 = c(14, 5, 11, 1, 22), V4 = c(0, 1, 8, -7, 7), V5 = c(10, 6, 9, 12, 14), V6 = c(-5, -19, -14, -2, -3), V7 = c(5, 11, 28, 3, 15)))
test <- cor(test_data)
diag(test) <- rep(0,nrow(test))
is_multicol(test_data)
m <- apply(test, 2, function(x) any(sapply(x, function(y) equal(abs(y),1))))
colnames(test)[m]
is_multicol <- function(d){
test <- cor(d)
diag(test) <- rep(0,nrow(test))
m <- apply(test, 2, function(x) sapply(x, function(y) equal(abs(y),1)))
res <- colnames(test)[m]
if (length(res) > 0) res else "There is no collinearity in the data"
}
is_multicol(test_data)
test_data <- as.data.frame(list(V1 = c(20, 11, 17, 7, 28), V2 = c(9, 23, 18, 6, 7), V3 = c(14, 5, 11, 1, 22), V4 = c(0, 1, 8, -7, 7), V5 = c(10, 6, 9, 12, 14), V6 = c(-5, -19, -14, -2, -3), V7 = c(5, 11, 28, 3, 15)))
d <- test_data
test <- cor(d)
diag(test) <- rep(0,nrow(test))
m <- apply(test, 2, function(x) sapply(x, function(y) equal(abs(y),1)))
res <- colnames(test)[m]
is_multicol <- function(d){
test <- cor(d)
diag(test) <- rep(0,nrow(test))
m <- apply(test, 2, function(x) any(sapply(x, function(y) equal(abs(y),1))))
res <- colnames(test)[m]
if (length(res) > 0) res else "There is no collinearity in the data"
}
test_data <- as.data.frame(list(V1 = c(20, 11, 17, 7, 28), V2 = c(9, 23, 18, 6, 7), V3 = c(14, 5, 11, 1, 22), V4 = c(0, 1, 8, -7, 7), V5 = c(10, 6, 9, 12, 14), V6 = c(-5, -19, -14, -2, -3), V7 = c(5, 11, 28, 3, 15)))
is_multicol(test_data)
test_data <- as.data.frame(list(V1 = c(9, 13, 4, 17, 30), V2 = c(-1, 5, 12, 8, 3), V3 = c(22, 1, 34, -3, 2), V4 = c(14, 18, 9, 22, 35), V5 = c(3, 9, 16, 12, 7), V6 = c(9, 16, 27, 10, 9)))
is_multicol(test_data)
test_data <- read.csv("https://stepik.org/media/attachments/course/524/Norris_1.csv")
is_multicol(test_data)
test_data <- read.csv("https://stepik.org/media/attachments/course/524/Norris_2.csv")
is_multicol(test_data)
test_data <- read.csv("https://stepik.org/media/attachments/course/524/Norris_3.csv")
is_multicol(test_data)
dist_matrix <- dist(swiss)
fit <- hclust(dist_matrix)
cluster <- cutree(fit, 2)
swiss$cluster <- factor(cluster)
swiss
library(ggplot2)
my_plot <- ggplot(swiss, aes(Education, Catholic, col = cluster))
my_plot
my_plot <- ggplot(swiss, aes(Education, Catholic, col = cluster))+geom_smooth()
my_plot
my_plot <- ggplot(swiss, aes(Education, Catholic, col = cluster))+geom_smooth()+geom_point()
my_plot
my_plot <- ggplot(swiss, aes(Education, Catholic, col = cluster))+geom_smooth(method = 'glm')+geom_point()
my_plot
lapply(sorted_list, function(s) s == final_list[1])
library(readxl)
setwd("D:/ВКР")
# считываем данные 2020 года
df_2020 <- read_xlsx('main_data.xlsx', sheet = '2020')
df_2020 <- df_2020[,0:7]
colnames(df_2020) <- c("subject", "VRP", "investments", "funds", "coeff", "research", "goods")
# считываем данные 2019 года
df_2019 <- read_xlsx('main_data.xlsx', sheet = '2019')
df_2019 <- df_2019[,0:7]
colnames(df_2019) <- c("subject", "VRP", "investments", "funds", "coeff", "research", "goods")
df_2019 <- df_2019[-c(22, 23, 63, 64, 65),]
read_data <- function(s){
df <- read_xlsx('main_data.xlsx', sheet = s)
df <- df[-c(1,20,24,25,33,42,50,65,69,70,71,73,84),0:7]
colnames(df) <- c("subject", "VRP", "investments", "funds", "coeff", "research", "goods")
df$coeff <- as.double(df$coeff)
df <- subset(df, select = -c(subject))
return(df)
}
df_2018 <- read_data('2018')
df_2017 <- read_data('2017')
df_2016 <- read_data('2016')
df_2015 <- read_data('2015')
df_2014 <- read_data('2014')
read_data_1 <- function(s){
df <- read_xlsx('main_data.xlsx', sheet = s)
df <- df[-c(1,20,24,25,33,36, 41,42,50,65,69,70,71,73,84),0:7]
colnames(df) <- c("subject", "VRP", "investments", "funds", "coeff", "research", "goods")
df$coeff <- as.double(df$coeff)
return(df)
}
df_2013 <- read_data_1('2013')
df_2012 <- read_data_1('2012')
df_2011 <- read_data_1('2011')
# список субъектов
subjects <- c(df_2020$subject)  #названия субъектов 82 шт.
subj_without <- c(df_2013$subject) #названия субъектов 80 шт. без Крыма
# удаление перового столбца
df_2020 <- subset(df_2020, select = -c(subject))
df_2019 <- subset(df_2019, select = -c(subject))
df_2013 <- subset(df_2013, select = -c(subject))
df_2012 <- subset(df_2012, select = -c(subject))
df_2011 <- subset(df_2011, select = -c(subject))
# стандартизируем все наблюдения
df_scale_2020 <- scale(df_2020)
df_scale_2019 <- scale(df_2019)
df_scale_2018 <- scale(df_2018)
df_scale_2017 <- scale(df_2017)
df_scale_2016 <- scale(df_2016)
df_scale_2015 <- scale(df_2015)
df_scale_2014 <- scale(df_2014)
df_scale_2013 <- scale(df_2013)
df_scale_2012 <- scale(df_2012)
df_scale_2011 <- scale(df_2011)
#kmeans для 2020
#список разбиений 2020 года
list_of_clust_2020 <- list()
list_of_sizes <- list()
for (i in 1:20) {
km_2020 <- kmeans(df_scale_2020, centers = 4)
list_of_clust_2020[[i]] = km_2020
list_of_sizes[[i]] = km_2020['size']
}
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
View(sorted_list)
final_list <- unique(sorted_list)
lapply(sorted_list, function(s) s == final_list[1])
final_list[1]
final_list[[1]]
lapply(sorted_list, function(s) s == final_list[[1]])
lapply(sorted_list, function(s) all(s == final_list[[1]]))
sum(lapply(sorted_list, function(s) all(s == final_list[[1]])))
sum(as.vector(lapply(sorted_list, function(s) all(s == final_list[[1]]))))
unlist(lapply(sorted_list, function(s) all(s == final_list[[1]])))
sum(unlist(lapply(sorted_list, function(s) all(s == final_list[[1]]))))
unique_list <- unique(sorted_list)
sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[1]]))))
paste(unique_list[[1]])
paste0(unique_list[[1]])
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
razb$un[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == un[[1]]))))
}
return(razb)
}
find_frequent(unique_list)
find_frequent(unique_list)
unique_list
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
razb$un[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == un[[i]]))))
}
return(razb)
}
find_frequent(unique_list)
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
a = un[[i]]
razb$a = sum(unlist(lapply(sorted_list, function(s) all(s == un[[i]]))))
}
return(razb)
}
find_frequent(unique_list)
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
a = un[[i]]
razb['a'] = sum(unlist(lapply(sorted_list, function(s) all(s == un[[i]]))))
}
return(razb)
}
find_frequent(unique_list)
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == un[[i]]))))
}
return(razb)
}
razbiyeniya <- find_frequent(unique_list)
razbiyeniya
cbind(unique_list, razbiyeniya)
?unique
unique_list[[1]]
cbind(unique_list, amount)
amount <- find_frequent(unique_list)
cbind(unique_list, amount)
unique_list[[1]]
unique_list[[5]]
#список моделей 2020 года
list_of_clust_2020 <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:20) {
km_2020 <- kmeans(df_scale_2020, centers = 4)
list_of_clust_2020[[i]] = km_2020
list_of_sizes[[i]] = km_2020['size']
}
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == un[[i]]))))
}
return(razb)
}
amount <- find_frequent(unique_list)
cbind(unique_list, amount)
unique_list[[2]]
unique_list[[1]]
unique_list[[3]]
unique_list[[4]]
unique_list[[5]]
#список моделей 2020 года
list_of_clust_2020 <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:20) {
km_2020 <- kmeans(df_scale_2020, centers = 4)
list_of_clust_2020[[i]] = km_2020
list_of_sizes[[i]] = km_2020['size']
}
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
find_frequent <- function(un){
razb <- list()
for (i in 1:length(un)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == un[[i]]))))
}
return(razb)
}
amount <- find_frequent(unique_list)
cbind(unique_list, amount)
unique_list[[52]]
unique_list[[2]]
lapply(sorted_list, function(s) all(s == unique_list[[2]]))
unlist(lapply(sorted_list, function(s) all(s == unique_list[[2]])))
list_of_clust_2020[[2]].['cluster']
list_of_clust_2020[[2]]['cluster']
mvp <- list_of_clust_2020[[2]]['cluster']
lapply(mvp['cluster'], function(s) which(s == 1))
# тут удобное определение регионов, входящих в кластер
first <-  lapply(mvp['cluster'], function(s) which(s == 1))
second <- lapply(mvp['cluster'], function(s) which(s == 2))
third <- lapply(mvp['cluster'], function(s) which(s == 3))
fourth <- lapply(mvp['cluster'], function(s) which(s == 4))
subjects[unlist(first)]
subjects[unlist(second)]
subjects[unlist(third)]
subjects[unlist(fourth)]
find_frequent <- function(num_models, df){
#список моделей
list_of_models <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:num_models) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
list_of_sizes[[i]] = km['size']
}
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
unique_list <- unique(sorted_list)
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(razb)
}
find_frequent(20,df_2020)
find_frequent(20,df_scale_2020)
find_frequent(20,df_scale_2020)
find_frequent <- function(num_models, df){
#список моделей
list_of_models <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:num_models) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
list_of_sizes[[i]] = km['size']
}
#список с отсортированными размерами кластеров
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
#подсчитаем сколько раз было осуществлено такое разбиение
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(razb)
}
find_frequent(20,df_scale_2020)
amount, unique_clust <- find_frequent(20, df_scale_2020)
find_frequent(20, df_scale_2020)
find_frequent <- function(num_models, df){
#список моделей
list_of_models <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:num_models) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
list_of_sizes[[i]] = km['size']
}
#список с отсортированными размерами кластеров
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
#подсчитаем сколько раз было осуществлено такое разбиение
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(razb, unique_list)
}
find_frequent(20, df_scale_2020)
find_frequent <- function(num_models, df){
#список моделей
list_of_models <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:num_models) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
list_of_sizes[[i]] = km['size']
}
#список с отсортированными размерами кластеров
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
#подсчитаем сколько раз было осуществлено такое разбиение
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(razb)
return(unique_list)
}
find_frequent(20, df_scale_2020)
find_frequent <- function(num_models, df){
#список моделей
list_of_models <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:num_models) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
list_of_sizes[[i]] = km['size']
}
#список с отсортированными размерами кластеров
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
#подсчитаем сколько раз было осуществлено такое разбиение
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(cbind(unique_list, razb))
}
find_frequent(20, df_scale_2020)
result <- find_frequent(20, df_scale_2020)
result[3,1]
result[2,1]
result[1,1]
result[4,1]
find_frequent <- function(num_models, df){
#список моделей
list_of_models <- list()
#список с размерами кластеров для каждой модели
list_of_sizes <- list()
for (i in 1:num_models) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
list_of_sizes[[i]] = km['size']
}
#список с отсортированными размерами кластеров
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
#подсчитаем сколько раз было осуществлено такое разбиение
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(cbind(list_of_models,unique_list, razb))
}
result <- find_frequent(20, df_scale_2020)
use_method <- function(n, df){
#список моделей
list_of_models <- list()
for (i in 1:n) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
}
return(list_of_models)
}
temp <- use_method(20,df_scale_2020)
temp1 <- lapply(temp, function(a) a['size'])
temp1
use_method <- function(n, df){
#список моделей
list_of_models <- list()
for (i in 1:n) {
km <- kmeans(df, centers = 4)
list_of_models[[i]] = km
}
return(list_of_models)
}
models_2020 <- use_method(20, df_scale_2020)
find_frequent <- function(models){
#список с размерами кластеров для каждой модели
list_of_sizes <- lapply(models, function(a) a['size'])
#список с отсортированными размерами кластеров
sorted_list <- lapply(list_of_sizes, function(s) {
l <- sort(unlist(s))
names(l) <- NULL
return(l)
})
#список уникальных разбиений
unique_list <- unique(sorted_list)
#подсчитаем сколько раз было осуществлено такое разбиение
razb <- list()
for (i in 1:length(unique_list)) {
razb[[i]] = sum(unlist(lapply(sorted_list, function(s) all(s == unique_list[[i]]))))
}
return(cbind(unique_list, razb))
}
models_2020 <- use_method(20, df_scale_2020)
result <- find_frequent(models_2020)
result[4,1]
result
result[2,1]
lapply(models_2020, function(s) s['cluster'])
lapply(models_2020, function(s) s['size'])
fviz_cluster(models_2020[[2]], data = df_scale_2020)
library(cluster)
library(factoextra)
fviz_cluster(models_2020[[2]], data = df_scale_2020)
# 2019 year
models_2019 <- use_method(20, df_scale_2019)
result <- find_frequent(models_2019)
result
result[2,1]
# определяю модель, дающую такое разбиение
lapply(models_2019, function(s) s['size'])
# визуализирую её
fviz_cluster(models_2019[[3]], data = df_scale_2019)
# визуализирую её
fviz_cluster(models_2019[[3]], data = df_scale_2019)
# тут удобное определение регионов, входящих в кластер
first <-  lapply(models_2019[[3]]['cluster'], function(s) which(s == 1))
first
subjects[unlist(first)]
second <- lapply(models_2019[[3]]['cluster'], function(s) which(s == 2))
subjects[unlist(second)]
